# -*- coding: utf-8 -*-
import os
import time
import math
import json
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
from io import BytesIO
from PIL import Image
import folium
from folium.plugins import TimestampedGeoJson
from branca.colormap import linear

# =========================
# CONFIG & CONSTANTS
# =========================
st.set_page_config(page_title="Hanoi Air Quality: 30-day Analysis", layout="wide")

# Báº¡n cÃ³ thá»ƒ thay báº±ng biáº¿n mÃ´i trÆ°á»ng náº¿u muá»‘n: os.environ.get("OWM_API_KEY")
OWM_API_KEY = "490f66c05505839fe0646bb5aa5770dc"
CITY_NAME = "Hanoi"
COUNTRY_CODE = "VN"
TARGET_DAYS = 30
CHUNK_DAYS = 5  # OWM free thÆ°á»ng chá»‰ cho 5 ngÃ y history/Ä‘á»£t
TIMEZONE = timezone(timedelta(hours=7))  # Asia/Bangkok (UTC+7)

# =========================
# UTILS
# =========================
@st.cache_data(show_spinner=False, ttl=3600)
def geocode_city(city, country, api_key):
    url = "https://api.openweathermap.org/geo/1.0/direct"
    params = {"q": f"{city},{country}", "limit": 1, "appid": api_key}
    r = requests.get(url, params=params, timeout=30)
    r.raise_for_status()
    js = r.json()
    if not js:
        raise ValueError("KhÃ´ng tÃ¬m tháº¥y toáº¡ Ä‘á»™ thÃ nh phá»‘.")
    lat, lon = js[0]["lat"], js[0]["lon"]
    return lat, lon, js[0]

def unix(dt):
    return int(dt.replace(tzinfo=timezone.utc).timestamp())

def to_local(ts):
    # OWM tráº£ dt lÃ  UNIX UTC
    return datetime.fromtimestamp(int(ts), tz=timezone.utc).astimezone(TIMEZONE)

@st.cache_data(show_spinner=True, ttl=1800)
def get_air_history(lat, lon, start_dt, end_dt, api_key):
    """
    Gá»i OWM Air Pollution History theo cÃ¡c cá»­a sá»• 5 ngÃ y Ä‘á»ƒ cá»‘ láº¥y Ä‘á»§ 30 ngÃ y.
    Tráº£ vá» list báº£n ghi (dict) tá»« API.
    """
    collected = []
    total_days = (end_dt - start_dt).days + 1
    # lÃ¹i theo cÃ¡c khung 5 ngÃ y
    window_end = end_dt
    while window_end > start_dt:
        window_start = max(start_dt, window_end - timedelta(days=CHUNK_DAYS-1))
        url = "https://api.openweathermap.org/data/2.5/air_pollution/history"
        params = {
            "lat": lat, "lon": lon,
            "start": unix(window_start.replace(hour=0, minute=0, second=0, microsecond=0)),
            "end": unix((window_end + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)),
            "appid": api_key
        }
        try:
            r = requests.get(url, params=params, timeout=45)
            if r.status_code == 429:
                # háº¡n má»©c -> nghá»‰ 2s rá»“i thá»­ láº¡i
                time.sleep(2)
                r = requests.get(url, params=params, timeout=45)
            r.raise_for_status()
            js = r.json()
            if isinstance(js, dict) and "list" in js:
                collected.extend(js["list"])
        except requests.HTTPError as e:
            # Náº¿u vÆ°á»£t giá»›i háº¡n lá»‹ch sá»­ (free), váº«n tiáº¿p tá»¥c vá»›i pháº§n láº¥y Ä‘Æ°á»£c
            st.info(f"âš ï¸ KhÃ´ng láº¥y Ä‘Æ°á»£c Ä‘oáº¡n {window_start.date()} â†’ {window_end.date()}: {e}")
        window_end = window_start - timedelta(days=1)
    # loáº¡i trÃ¹ng theo timestamp
    seen = set()
    uniq = []
    for it in collected:
        t = int(it.get("dt", -1))
        if t not in seen and t != -1:
            uniq.append(it)
            seen.add(t)
    # sort theo thá»i gian
    uniq.sort(key=lambda x: x.get("dt", 0))
    return uniq

def normalize_dataframe(raw_list, lat, lon):
    if not raw_list:
        return pd.DataFrame()
    rows = []
    for it in raw_list:
        dt_utc = int(it.get("dt", 0))
        main = it.get("main", {}) or {}
        comps = it.get("components", {}) or {}
        rows.append({
            "dt_utc": dt_utc,
            "time": to_local(dt_utc),
            "aqi": main.get("aqi", np.nan),
            "co": comps.get("co", np.nan),
            "no": comps.get("no", np.nan),
            "no2": comps.get("no2", np.nan),
            "o3": comps.get("o3", np.nan),
            "so2": comps.get("so2", np.nan),
            "pm2_5": comps.get("pm2_5", np.nan),
            "pm10": comps.get("pm10", np.nan),
            "nh3": comps.get("nh3", np.nan),
            "lat": lat, "lon": lon
        })
    df = pd.DataFrame(rows).drop_duplicates(subset=["dt_utc"]).sort_values("time").reset_index(drop=True)

    # Chuáº©n hoÃ¡ kiá»ƒu dá»¯ liá»‡u
    num_cols = ["aqi","co","no","no2","o3","so2","pm2_5","pm10","nh3","lat","lon"]
    for c in num_cols:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # Xá»­ lÃ½ thiáº¿u: forward-fill theo giá» (vÃ¬ cÃ¹ng 1 Ä‘iá»ƒm Ä‘o)
    if not df.empty:
        df = df.set_index("time")
        df[num_cols] = df[num_cols].interpolate(method="time", limit_direction="both")
        df = df.reset_index()

    # Táº¡o Ä‘áº·c trÆ°ng má»›i
    if not df.empty:
        df["pm_ratio"] = df["pm2_5"] / df["pm10"]
        df["hour"] = df["time"].dt.hour
        df["day"] = df["time"].dt.date.astype(str)
        df["weekday"] = df["time"].dt.day_name()
        df["is_weekend"] = df["weekday"].isin(["Saturday","Sunday"]).astype(int)
        df["rolling_pm25_24h"] = df["pm2_5"].rolling(24, min_periods=6).mean()
        df["rolling_pm10_24h"] = df["pm10"].rolling(24, min_periods=6).mean()
        df["aqi_label"] = df["aqi"].map({
            1:"Good", 2:"Fair", 3:"Moderate", 4:"Poor", 5:"Very Poor"
        }).fillna("Unknown")
    return df

def corr_df(df):
    cols = ["aqi","co","no","no2","o3","so2","pm2_5","pm10","nh3","pm_ratio","rolling_pm25_24h","rolling_pm10_24h"]
    cols = [c for c in cols if c in df.columns]
    return df[cols].corr().round(3)

def summarize_insight(df):
    if df.empty:
        return {
            "n": 0, "date_range": "No data",
            "max_pm25": None, "max_pm25_time": None,
            "bad_hours_share": None,
            "mean_pm25": None, "median_pm25": None,
            "top_day": None
        }
    # Thá»‘ng kÃª cÆ¡ báº£n
    n = len(df)
    dr = f"{df['time'].min().date()} â†’ {df['time'].max().date()}"
    idx_max = df["pm2_5"].idxmax()
    time_max = df.loc[idx_max, "time"]
    max_pm25 = df.loc[idx_max, "pm2_5"]
    bad_hours_share = (df["aqi"] >= 4).mean()  # tá»‰ lá»‡ giá» 'Poor' & 'Very Poor'
    mean_pm25 = df["pm2_5"].mean()
    median_pm25 = df["pm2_5"].median()
    daily = df.groupby("day")["pm2_5"].mean().sort_values(ascending=False)
    top_day = daily.index[0] if len(daily) else None
    return {
        "n": n, "date_range": dr,
        "max_pm25": float(max_pm25), "max_pm25_time": time_max.strftime("%Y-%m-%d %H:%M"),
        "bad_hours_share": float(bad_hours_share),
        "mean_pm25": float(mean_pm25), "median_pm25": float(median_pm25),
        "top_day": top_day
    }

def make_wordcloud(text_series):
    txt = " ".join([str(x) for x in text_series if pd.notna(x)])
    if not txt.strip():
        return None
    wc = WordCloud(width=1200, height=600, background_color="white").generate(txt)
    bio = BytesIO()
    wc.to_image().save(bio, format="PNG")
    bio.seek(0)
    return Image.open(bio)

# =========================
# SIDEBAR
# =========================
st.sidebar.title("âš™ï¸ Controls")
st.sidebar.write("PhÃ¢n tÃ­ch cháº¥t lÆ°á»£ng khÃ´ng khÃ­ táº¡i **HÃ  Ná»™i** (OWM).")
target_days = st.sidebar.slider("Sá»‘ ngÃ y gáº§n nháº¥t", 7, 30, TARGET_DAYS, 1)
show_regression = st.sidebar.checkbox("Scatter + OLS regression", True)
use_treemap = st.sidebar.selectbox("PhÃ¢n cáº¥p", ["Sunburst AQI â†’ Weekday", "Treemap AQI â†’ Hour"], index=0)
map_mode = st.sidebar.selectbox("Báº£n Ä‘á»“", ["Folium (Timestamped)", "Plotly Mapbox"], index=0)

# =========================
# DATA FETCH
# =========================
st.title("ğŸŒ«ï¸ Hanoi Air Quality â€” 30-day Analysis (OpenWeatherMap)")
st.caption("Nguá»“n: OpenWeatherMap Air Pollution API. á»¨ng dá»¥ng sáº½ tá»± bÃ¡o náº¿u chá»‰ láº¥y Ä‘Æ°á»£c â‰¤5 ngÃ y do giá»›i háº¡n gÃ³i.")

# Geocode
lat, lon, geo_meta = geocode_city(CITY_NAME, COUNTRY_CODE, OWM_API_KEY)

# Time window
end_local = datetime.now(tz=TIMEZONE)
start_local = end_local - timedelta(days=target_days-1)
# OWM history dÃ¹ng UTC
start_utc = start_local.astimezone(timezone.utc).replace(minute=0, second=0, microsecond=0)
end_utc = end_local.astimezone(timezone.utc).replace(minute=0, second=0, microsecond=0)

raw = get_air_history(lat, lon, start_utc, end_utc, OWM_API_KEY)
df = normalize_dataframe(raw, lat, lon)

if df.empty:
    st.error("KhÃ´ng láº¥y Ä‘Æ°á»£c dá»¯ liá»‡u tá»« OWM. HÃ£y kiá»ƒm tra API key/quyá»n truy cáº­p hoáº·c thá»­ láº¡i sau.")
    st.stop()

# Cáº£nh bÃ¡o náº¿u Ä‘á»™ phá»§ < 30 ngÃ y
got_days = (df["time"].max().date() - df["time"].min().date()).days + 1
if got_days < target_days - 1:
    st.warning(f"Chá»‰ láº¥y Ä‘Æ°á»£c ~{got_days} ngÃ y dá»¯ liá»‡u (giá»›i háº¡n API). Váº«n tiáº¿n hÃ nh phÃ¢n tÃ­ch trÃªn pháº§n dá»¯ liá»‡u nÃ y.")

# =========================
# SUMMARY KPIs & STORYTELLING
# =========================
kpi = summarize_insight(df)
c1, c2, c3, c4 = st.columns(4)
c1.metric("Khoáº£ng thá»i gian", kpi["date_range"])
c2.metric("Sá»‘ báº£n ghi (giá»)", f"{kpi['n']:,}")
c3.metric("PM2.5 cao nháº¥t (Âµg/mÂ³)", f"{kpi['max_pm25']:.1f}" if kpi["max_pm25"] else "â€”", help=f"Thá»i Ä‘iá»ƒm: {kpi['max_pm25_time'] or 'â€”'}")
c4.metric("Tá»‰ lá»‡ giá» AQI xáº¥u (â‰¥Poor)", f"{kpi['bad_hours_share']*100:.1f}%" if kpi["bad_hours_share"] is not None else "â€”")

with st.expander("ğŸ§¾ 1 trang storytelling (insights chÃ­nh)"):
    st.markdown(f"""
**Bá»‘i cáº£nh.** PhÃ¢n tÃ­ch chuá»—i thá»i gian cháº¥t lÆ°á»£ng khÃ´ng khÃ­ á»Ÿ HÃ  Ná»™i trong giai Ä‘oáº¡n **{kpi['date_range']}**.  
**Quy mÃ´ dá»¯ liá»‡u.** {kpi['n']:,} quan sÃ¡t giá».  
**Má»©c Ã´ nhiá»…m Ä‘Ã¡ng chÃº Ã½.** PM2.5 cao nháº¥t Ä‘áº¡t **{kpi['max_pm25']:.1f} Âµg/mÂ³** vÃ o **{kpi['max_pm25_time']}**.  
**Rá»§i ro phÆ¡i nhiá»…m.** Tá»‰ lá»‡ giá» cÃ³ AQI **tá»« má»©c Poor trá»Ÿ lÃªn** ~ **{kpi['bad_hours_share']*100:.1f}%**.  
**NgÃ y tá»‡ nháº¥t (theo PM2.5 trung bÃ¬nh ngÃ y).** **{kpi['top_day']}**.  

**Insight nhanh:**
- **Nhá»‹p ngÃ yâ€“Ä‘Ãªm:** So sÃ¡nh PM2.5 theo giá» cho tháº¥y cÃ¡c Ä‘á»‰nh thÆ°á»ng rÆ¡i vÃ o buá»•i **sÃ¡ng sá»›m** vÃ /hoáº·c **tá»‘i**, gá»£i Ã½ áº£nh hÆ°á»Ÿng giao thÃ´ng â€“ nghá»‹ch nhiá»‡t.  
- **TÆ°Æ¡ng quan PM2.5â€“PM10:** Há»‡ sá»‘ tÆ°Æ¡ng quan cao â†’ nguá»“n háº¡t má»‹n vÃ  thÃ´ cÃ¹ng biáº¿n thiÃªn; **pm_ratio** giÃºp nháº­n diá»‡n Æ°u tháº¿ háº¡t má»‹n.  
- **Äá»™ trá»… 24h:** Trung bÃ¬nh trÆ°á»£t 24h lÃ m mÆ°á»£t biáº¿n Ä‘á»™ng, há»¯u Ã­ch Ä‘á»ƒ cáº£nh bÃ¡o sá»›m náº¿u xu hÆ°á»›ng tÄƒng kÃ©o dÃ i.

> LÆ°u Ã½: Náº¿u báº¡n dÃ¹ng gÃ³i OWM tráº£ phÃ­, dá»¯ liá»‡u 30 ngÃ y sáº½ Ä‘áº§y Ä‘á»§ hÆ¡n; báº£n hiá»‡n táº¡i cÃ³ thá»ƒ bá»‹ giá»›i háº¡n â‰¤5 ngÃ y.
""")

# =========================
# CHARTS â€” INTERACTIVE (â‰¥3)
# =========================

# 1) Line/Area theo thá»i gian (Plotly)
st.subheader("ğŸ“ˆ PM2.5 & PM10 theo thá»i gian")
fig_area = go.Figure()
fig_area.add_trace(go.Scatter(x=df["time"], y=df["pm2_5"], mode="lines", name="PM2.5", fill="tozeroy"))
fig_area.add_trace(go.Scatter(x=df["time"], y=df["pm10"], mode="lines", name="PM10", fill=None))
fig_area.update_layout(xaxis_title="Time", yaxis_title="Âµg/mÂ³", hovermode="x unified")
st.plotly_chart(fig_area, use_container_width=True)

# 2) Histogram/Box/Violin (Plotly)
st.subheader("ğŸ“¦ PhÃ¢n phá»‘i PM2.5")
tab_hist, tab_box, tab_violin = st.tabs(["Histogram", "Boxplot", "Violin"])
with tab_hist:
    st.plotly_chart(px.histogram(df, x="pm2_5", nbins=40, marginal="rug", title="Histogram PM2.5"), use_container_width=True)
with tab_box:
    st.plotly_chart(px.box(df, y="pm2_5", points="all", title="Boxplot PM2.5"), use_container_width=True)
with tab_violin:
    st.plotly_chart(px.violin(df, y="pm2_5", box=True, points="all", title="Violin PM2.5"), use_container_width=True)

# 3) Scatter + há»“i quy (Plotly trendline=ols)
st.subheader("ğŸ”¬ PM2.5 vs PM10 (Scatter + OLS)")
trend = "ols" if show_regression else None
scatter_fig = px.scatter(df, x="pm2_5", y="pm10", opacity=0.7,
                         trendline=trend, trendline_color_override="black",
                         labels={"pm2_5":"PM2.5 (Âµg/mÂ³)", "pm10":"PM10 (Âµg/mÂ³)"},
                         hover_data=["time"])
st.plotly_chart(scatter_fig, use_container_width=True)

# 4) Heatmap tÆ°Æ¡ng quan
st.subheader("ğŸ§ª TÆ°Æ¡ng quan cÃ¡c chá»‰ tiÃªu")
corr = corr_df(df)
heat = px.imshow(corr, text_auto=True, aspect="auto", title="Correlation Heatmap")
st.plotly_chart(heat, use_container_width=True)

# 5) Sunburst/Treemap
st.subheader("ğŸª… PhÃ¢n cáº¥p AQI")
if use_treemap.startswith("Sunburst"):
    sb = px.sunburst(df, path=["aqi_label","weekday"], values=None, title="Sunburst: AQI â†’ Weekday")
    st.plotly_chart(sb, use_container_width=True)
else:
    # Treemap AQI â†’ Hour buckets
    df["hour_bin"] = pd.cut(df["hour"], bins=[-0.1,6,12,18,24], labels=["0â€“6","6â€“12","12â€“18","18â€“24"])
    tm = px.treemap(df, path=["aqi_label","hour_bin"], title="Treemap: AQI â†’ Hour")
    st.plotly_chart(tm, use_container_width=True)

# 6) Báº£n Ä‘á»“ (Folium hoáº·c Mapbox)
st.subheader("ğŸ—ºï¸ Báº£n Ä‘á»“")
if map_mode.startswith("Folium"):
    # Táº¡o geojson thá»i gian â€” 1 Ä‘iá»ƒm/giá», bÃ¡n kÃ­nh theo PM2.5
    m = folium.Map(location=[lat, lon], zoom_start=11, tiles="cartodbpositron")
    # thang mÃ u theo PM2.5
    cm = linear.YlOrRd_09.scale(df["pm2_5"].min(), df["pm2_5"].max())
    features = []
    for _, r in df.iterrows():
        t_iso = r["time"].isoformat()
        pm = float(r["pm2_5"])
        rad = max(50, min(500, pm*5))  # bÃ¡n kÃ­nh theo pm2.5
        color = cm(pm)
        feat = {
            "type": "Feature",
            "geometry": {"type":"Point","coordinates":[r["lon"], r["lat"]]},
            "properties": {
                "time": t_iso,
                "style": {"color": color, "fillColor": color, "opacity":0.7, "fillOpacity":0.4},
                "icon": "circle",
                "popup": f"{t_iso}<br>PM2.5: {pm:.1f} Âµg/mÂ³"
            }
        }
        features.append(feat)
    gj = {
        "type": "FeatureCollection",
        "features": features
    }
    TimestampedGeoJson(
        data=gj,
        period="PT1H",
        duration="PT1H",
        add_last_point=True,
        auto_play=False,
        loop=False
    ).add_to(m)
    cm.add_to(m)
    st.components.v1.html(m._repr_html_(), height=520, scrolling=False)
else:
    # Plotly mapbox scatter â€” cáº§n mapbox token náº¿u muá»‘n style map Ä‘áº¹p, máº·c Ä‘á»‹nh váº«n cháº¡y
    mb = px.scatter_mapbox(df, lat="lat", lon="lon", size="pm2_5",
                           color="pm2_5", hover_name="time",
                           zoom=10, height=520)
    mb.update_layout(mapbox_style="open-street-map", margin=dict(l=0,r=0,t=0,b=0))
    st.plotly_chart(mb, use_container_width=True)

# =========================
# WORDCLOUD hoáº·c NETWORK GRAPH
# =========================
st.subheader("â˜ï¸ WordCloud tá»« nhÃ£n AQI (láº·p theo táº§n suáº¥t)")
wc_img = make_wordcloud(df["aqi_label"])
if wc_img is not None:
    st.image(wc_img, caption="WordCloud vá» nhÃ£n AQI", use_column_width=True)
else:
    st.info("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u vÄƒn báº£n Ä‘á»ƒ táº¡o WordCloud.")

# =========================
# EXTRA: Báº¢NG Dá»® LIá»†U & Táº¢I XUá»NG
# =========================
st.subheader("ğŸ“„ Dá»¯ liá»‡u Ä‘Ã£ chuáº©n hoÃ¡")
st.dataframe(df.tail(500), use_container_width=True)

@st.cache_data
def to_csv_bytes(df_in):
    return df_in.to_csv(index=False).encode("utf-8")

st.download_button("â¬‡ï¸ Táº£i CSV", data=to_csv_bytes(df), file_name="hanoi_air_quality.csv", mime="text/csv")

# =========================
# FOOTER NOTES
# =========================
st.caption("""
- **Xá»­ lÃ½ thiáº¿u**: ná»™i suy theo thá»i gian & forward/backward fill (Ä‘iá»ƒm Ä‘o cá»‘ Ä‘á»‹nh).
- **Äáº·c trÆ°ng má»›i**: `pm_ratio` (PM2.5/PM10), `rolling_pm25_24h`, `rolling_pm10_24h`, nhÃ£n `aqi_label`, biáº¿n thá»i gian (giá», weekday, weekend).
- **Háº¡n cháº¿ API**: Náº¿u gÃ³i OWM khÃ´ng cho Ä‘á»§ 30 ngÃ y, á»©ng dá»¥ng váº«n cháº¡y vá»›i pháº§n dá»¯ liá»‡u hiá»‡n cÃ³.
""")
